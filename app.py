import re
import json
import urllib.parse
import urllib.request
import urllib.error
from datetime import datetime
import io
import csv

import streamlit as st
import streamlit.components.v1 as components
import pyphen

# ================== åŸºç¡€è®¾ç½® ==================

st.set_page_config(page_title="Phonics è‹±è¯­éŸ³èŠ‚å·¥å…·", page_icon="ğŸ”¤")

# è‹±è¯­ï¼ˆç¾å¼ï¼‰éŸ³èŠ‚æ‹†åˆ†å™¨
dic = pyphen.Pyphen(lang="en_US")

# åˆå§‹åŒ– session_state
if "input_box_id" not in st.session_state:
    st.session_state["input_box_id"] = 0

# å­—å…¸ç¼“å­˜ï¼šé¿å…å¯¹åŒä¸€ä¸ªå•è¯é‡å¤è¯·æ±‚ API
# { word_lower: { "ipa": str|None, "pos": str|None, "definition": str|None,
#                 "example": str|None, "synonyms": list[str] } }
if "dict_cache" not in st.session_state:
    st.session_state["dict_cache"] = {}

# å†å²è®°å½•ï¼šæŒ‰â€œæ ‡å‡†å•è¯â€å»é‡
# { base_word: { æ—¶é—´, æ¬¡æ•°, åŸå§‹è¾“å…¥, æ ‡å‡†å•è¯, éŸ³èŠ‚åˆ†éš”, éŸ³èŠ‚æ•°, IPA } }
if "history" not in st.session_state:
    st.session_state["history"] = {}


# ================== åˆ†éŸ³èŠ‚è§„åˆ™è§£é‡Šå™¨ï¼ˆç®€å•ç‰ˆï¼‰ ==================

def explain_syllable_rules(word: str, syllables: list[str]) -> list[str]:
    """
    ç®€æ˜“ç‰ˆåˆ†éŸ³èŠ‚è§„åˆ™è§£é‡Šå™¨ï¼ˆä¸ä¾èµ– IPAï¼‰
    æ ¹æ®å•è¯æ‹¼å†™å’Œæ‹†å‡ºçš„éŸ³èŠ‚ï¼Œç”Ÿæˆå‡ æ¡å¯è¯»çš„è§„åˆ™è¯´æ˜ã€‚
    """
    rules: list[str] = []
    base = word.lower()

    # å›ºå®šåç¼€è§„åˆ™
    suffix_rules = {
        "tion": "åç¼€ -tion é€šå¸¸æ„æˆä¸€ä¸ªç‹¬ç«‹éŸ³èŠ‚",
        "sion": "åç¼€ -sion é€šå¸¸æ„æˆä¸€ä¸ªç‹¬ç«‹éŸ³èŠ‚",
        "ing": "åç¼€ -ing é€šå¸¸æ„æˆä¸€ä¸ªç‹¬ç«‹éŸ³èŠ‚",
        "er": "åç¼€ -er å¸¸å•ç‹¬æˆéŸ³èŠ‚ï¼ˆå¦‚ teacher, computerï¼‰",
        "or": "åç¼€ -or å¸¸å•ç‹¬æˆéŸ³èŠ‚ï¼ˆå¦‚ actor, doctorï¼‰",
        "ment": "åç¼€ -ment å¸¸ä½œä¸ºç‹¬ç«‹éŸ³èŠ‚ï¼ˆå¦‚ movementï¼‰",
        "ness": "åç¼€ -ness å¸¸ä½œä¸ºç‹¬ç«‹éŸ³èŠ‚ï¼ˆå¦‚ kindnessï¼‰",
        "able": "åç¼€ -able é€šå¸¸ä¸ºç‹¬ç«‹éŸ³èŠ‚ï¼ˆå¦‚ comfortableï¼‰",
        "ible": "åç¼€ -ible é€šå¸¸ä¸ºç‹¬ç«‹éŸ³èŠ‚ï¼ˆå¦‚ possibleï¼‰",
    }

    for suf, text in suffix_rules.items():
        if base.endswith(suf):
            rules.append(f"Â· {text}")
            break

    # åŒè¾…éŸ³æ–­ç‚¹ï¼ˆVCC â†’ VC-Cï¼‰
    if re.search(r"[aeiou][bcdfghjklmnpqrstvwxyz]{2}", base):
        rules.append("Â· VCC ç»“æ„ä¸­ï¼Œå…ƒéŸ³åè·Ÿä¸¤ä¸ªè¾…éŸ³æ—¶ï¼Œä¸€èˆ¬åœ¨ç¬¬ä¸€ä¸ªè¾…éŸ³åæ–­å¼€ï¼ˆV-C-Cï¼‰")

    # CVC ç»“æ„
    if re.search(r"[bcdfghjklmnpqrstvwxyz][aeiou][bcdfghjklmnpqrstvwxyz]", base):
        rules.append("Â· CVC ç»“æ„ä¸­ï¼ŒçŸ­å…ƒéŸ³åå¾€å¾€åœ¨è¾…éŸ³å¤„æ–­å¼€ï¼Œå½¢æˆä¸€ä¸ªè‡ªç„¶éŸ³èŠ‚")

    # å¤šéŸ³èŠ‚æé†’
    if len(syllables) >= 3:
        rules.append("Â· å¤šéŸ³èŠ‚å•è¯é€šå¸¸ä»å·¦åˆ°å³æŒ‰å‘éŸ³èŠ‚å¥è‡ªç„¶åˆ†æ®µ")

    # æ²¡å‘½ä¸­ä»»ä½•è§„åˆ™ï¼Œç»™ä¸€ä¸ªå…œåº•æç¤º
    if not rules:
        rules.append("Â· æ ¹æ®å¸¸è§å‘éŸ³èŠ‚å¥æ‹†åˆ†éŸ³èŠ‚ï¼ˆæœ¬è¯ä¸å±äºå¸¸è§è§„åˆ™èŒƒç•´ï¼‰")

    return rules


# ================== å­—å…¸ APIï¼šè·å– IPA + é‡Šä¹‰ + ä¾‹å¥ + åŒä¹‰è¯ ==================

def fetch_word_info_from_api(word: str):
    """
    å‘å…è´¹å­—å…¸ API è¯·æ±‚è¯¥å•è¯çš„è¯¦ç»†ä¿¡æ¯ï¼š
    - IPA éŸ³æ ‡
    - è¯æ€§ï¼ˆpart of speechï¼‰
    - ç¬¬ä¸€æ¡è‹±æ–‡é‡Šä¹‰
    - ä¸€ä¸ªä¾‹å¥
    - åŒä¹‰è¯åˆ—è¡¨
    æŸ¥ä¸åˆ°æˆ–ç½‘ç»œå¼‚å¸¸æ—¶ï¼Œè¿”å›ä¸€ä¸ªå­—æ®µéƒ½ä¸º None çš„ dictã€‚
    """
    base_result = {
        "ipa": None,
        "pos": None,
        "definition": None,
        "example": None,
        "synonyms": [],
    }

    try:
        url = (
            "https://api.dictionaryapi.dev/api/v2/entries/en/"
            + urllib.parse.quote(word)
        )
        with urllib.request.urlopen(url, timeout=5) as resp:
            if resp.status != 200:
                return base_result
            data = resp.read().decode("utf-8")
        js = json.loads(data)
    except (urllib.error.URLError, TimeoutError, json.JSONDecodeError, Exception):
        return base_result

    # æ­£å¸¸æƒ…å†µä¸‹æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼š[{...}]
    if not (isinstance(js, list) and js):
        return base_result

    entry = js[0]

    # -------- IPA --------
    ipa = entry.get("phonetic")
    if not ipa:
        phonetics = entry.get("phonetics") or []
        if isinstance(phonetics, list):
            for p in phonetics:
                text = p.get("text")
                if isinstance(text, str) and text.strip():
                    ipa = text.strip()
                    break
    if isinstance(ipa, str) and ipa.strip():
        ipa = ipa.strip()
        # ä¸€èˆ¬ API ä¼šè‡ªå¸¦æ–œæ ï¼Œå¦‚æœæ²¡æœ‰ï¼Œæˆ‘ä»¬è¡¥ä¸€ä¸ª
        if not (ipa.startswith("/") or ipa.startswith("[")):
            ipa = f"/{ipa}/"
        base_result["ipa"] = ipa

    # -------- meanings: è¯æ€§ + é‡Šä¹‰ + ä¾‹å¥ + åŒä¹‰è¯ --------
    meanings = entry.get("meanings") or []
    if isinstance(meanings, list) and meanings:
        m = meanings[0]  # åªçœ‹ç¬¬ä¸€æ¡å¤§ç±»
        pos = m.get("partOfSpeech")
        if isinstance(pos, str) and pos.strip():
            base_result["pos"] = pos.strip()

        defs = m.get("definitions") or []
        if isinstance(defs, list) and defs:
            d0 = defs[0]
            # é‡Šä¹‰
            definition = d0.get("definition")
            if isinstance(definition, str) and definition.strip():
                base_result["definition"] = definition.strip()

            # ä¾‹å¥
            example = d0.get("example")
            if isinstance(example, str) and example.strip():
                base_result["example"] = example.strip()

            # åŒä¹‰è¯
            syns = d0.get("synonyms") or []
            if isinstance(syns, list):
                uniq = []
                for s in syns:
                    if isinstance(s, str):
                        s_clean = s.strip()
                        if s_clean and s_clean not in uniq:
                            uniq.append(s_clean)
                base_result["synonyms"] = uniq[:5]

    return base_result


def get_word_info(word: str):
    """
    å¯¹å¤–æ¥å£ï¼šå…ˆæŸ¥ç¼“å­˜ï¼Œæ²¡æœ‰å†è¯·æ±‚ APIã€‚
    è¿”å› dict:
    {
      "ipa": str|None,
      "pos": str|None,
      "definition": str|None,
      "example": str|None,
      "synonyms": [str, ...]
    }
    """
    cache = st.session_state["dict_cache"]
    key = word.lower()
    if key in cache:
        return cache[key]

    info = fetch_word_info_from_api(key)
    cache[key] = info
    return info


# ================== é¡¶éƒ¨æ ‡é¢˜åŒºåŸŸ ==================

st.markdown(
    """
    <h1 style="text-align:center; margin-bottom:0.2rem;">Phonics è‹±è¯­éŸ³èŠ‚å·¥å…·</h1>
    <p style="text-align:center; color:#9CA3AF; font-size:0.9rem;">
      æ‹†éŸ³èŠ‚ Â· çœ‹éŸ³æ ‡ Â· å¬å‘éŸ³ Â· æŸ¥é‡Šä¹‰ Â· å¯è§†åŒ–åˆ†éŸ³èŠ‚è§„åˆ™ Â· è‡ªåŠ¨ç”Ÿæˆä½ çš„ä¸“å±å•è¯æœ¬
    </p>
    <hr style="margin-top:0.8rem; margin-bottom:1.2rem; border-color:#374151;">
    """,
    unsafe_allow_html=True,
)

# è¾“å…¥åŒº + å³ä¾§ä½¿ç”¨æç¤º
col_left, col_right = st.columns([2, 1])

with col_left:
    # å½“å‰è¿™ä¸€è½®è¾“å…¥æ¡†ä½¿ç”¨çš„ keyï¼ˆç”¨äºâ€œæ¸…ç©ºâ€ï¼‰
    input_key = f"user_input_{st.session_state['input_box_id']}"
    text = st.text_input("è¯·è¾“å…¥è‹±æ–‡å•è¯æˆ–å¥å­ï¼š", key=input_key)

    if st.button("æ¸…ç©ºå½“å‰è¾“å…¥"):
        st.session_state["input_box_id"] += 1
        st.rerun()

with col_right:
    st.markdown(
        """
        <div style="padding:0.75rem 0.9rem; border-radius:0.75rem;
                    background-color:#111827; border:1px solid #1F2937; font-size:0.85rem;">
          <b>ä½¿ç”¨æç¤º</b><br/>
          Â· æ”¯æŒä¸€æ¬¡è¾“å…¥å¤šä¸ªå•è¯æˆ–ä¸€ä¸ªçŸ­å¥ï¼›<br/>
          Â· æ¯ä¸ªå•è¯ä¼šæ‹†éŸ³èŠ‚ï¼Œå¹¶ç»™å‡º IPAã€é‡Šä¹‰ã€ä¾‹å¥å’Œå‘éŸ³ï¼›<br/>
          Â· ä¼šè‡ªåŠ¨ç»™å‡ºç®€å•çš„â€œåˆ†éŸ³èŠ‚è§„åˆ™â€è¯´æ˜ï¼Œå¸®åŠ©ç†è§£ä¸ºä»€ä¹ˆè¿™æ ·æ‹†ï¼›<br/>
          Â· ä¸‹æ–¹ä¼šè‡ªåŠ¨è®°å½•å†å²ï¼Œå¯å¯¼å‡ºä¸º CSV / TXT ç”¨ä½œå•è¯æœ¬ã€‚
        </div>
        """,
        unsafe_allow_html=True,
    )

st.write("")  # å°é—´è·

# ================== ä¸»é€»è¾‘ï¼šæ‹†éŸ³èŠ‚ + IPA + é‡Šä¹‰ + è§„åˆ™ + å‘éŸ³ ==================

if text.strip():
    words = text.strip().split()
    total_syllables = 0
    total_words = 0

    st.markdown("### æ‹†éŸ³èŠ‚ã€éŸ³æ ‡ã€é‡Šä¹‰ä¸è§„åˆ™è¯´æ˜")

    for w in words:
        # å»æ‰æ ‡ç‚¹ï¼Œåªä¿ç•™å­—æ¯å’Œ '
        clean_word = re.sub(r"[^A-Za-z']", "", w)
        if not clean_word:
            continue

        base = clean_word.lower()
        total_words += 1

        # æ‹†éŸ³èŠ‚
        hyphenated = dic.inserted(base)          # e.g. computer -> com-put-er
        syllables = hyphenated.split("-")
        cnt = len(syllables)
        total_syllables += cnt
        pretty = "Â·".join(syllables)            # comÂ·putÂ·er

        # ======== å­—å…¸ä¿¡æ¯ï¼šIPA + é‡Šä¹‰ + ä¾‹å¥ + åŒä¹‰è¯ ========
        info = get_word_info(base)
        ipa_text = info.get("ipa")
        pos = info.get("pos")
        definition = info.get("definition")
        example = info.get("example")
        synonyms = info.get("synonyms") or []

        # ======== åˆ†éŸ³èŠ‚è§„åˆ™è§£é‡Š ========
        rules = explain_syllable_rules(base, syllables)

        # ======== å•è¯å¡ç‰‡ UI ========
        card_html = f"""
        <div style="padding:0.75rem 1rem; margin-bottom:0.8rem; border-radius:0.9rem;
                    background-color:#020617; border:1px solid #1E293B;">
          <div style="font-size:1.1rem; font-weight:600; margin-bottom:0.25rem;">
            {w}
          </div>
          <div style="color:#E5E7EB; margin-bottom:0.15rem;">
            {pretty}ï¼ˆ{cnt} ä¸ªéŸ³èŠ‚ï¼‰
          </div>
        """

        # IPA
        if ipa_text:
            card_html += (
                f'<div style="color:#A5B4FC; font-size:0.9rem; margin-bottom:0.15rem;">'
                f'éŸ³æ ‡ï¼ˆIPAï¼‰ï¼š<code>{ipa_text}</code></div>'
            )

        # é‡Šä¹‰ï¼ˆå¸¦è¯æ€§ï¼‰
        if definition:
            if pos:
                card_html += (
                    f'<div style="color:#D1D5DB; font-size:0.9rem; margin-top:0.15rem;">'
                    f'<b>é‡Šä¹‰ï¼š</b><i>{pos}</i> â€“ {definition}'
                    f'</div>'
                )
            else:
                card_html += (
                    f'<div style="color:#D1D5DB; font-size:0.9rem; margin-top:0.15rem;">'
                    f'<b>é‡Šä¹‰ï¼š</b>{definition}</div>'
                )

        # ä¾‹å¥
        if example:
            card_html += (
                f'<div style="color:#9CA3AF; font-size:0.85rem; margin-top:0.15rem;">'
                f'<b>ä¾‹å¥ï¼š</b>{example}</div>'
            )

        # åŒä¹‰è¯
        if synonyms:
            syn_str = ", ".join(synonyms)
            card_html += (
                f'<div style="color:#FBBF24; font-size:0.85rem; margin-top:0.15rem;">'
                f'<b>åŒä¹‰è¯ï¼š</b>{syn_str}</div>'
            )

        # åˆ†éŸ³èŠ‚è§„åˆ™è¯´æ˜å—
        rule_html = (
            "<div style='color:#60A5FA; font-size:0.85rem; "
            "margin-top:0.25rem;'><b>åˆ†éŸ³èŠ‚è§„åˆ™ï¼ˆç®€è¦ï¼‰ï¼š</b><br/>"
        )
        for r in rules:
            rule_html += f"{r}<br/>"
        rule_html += "</div>"

        card_html += rule_html
        card_html += "</div>"

        st.markdown(card_html, unsafe_allow_html=True)

        # ======== å‘éŸ³ï¼ˆæœ‰é“ MP3ï¼‰ ========
        audio_url = (
            "https://dict.youdao.com/dictvoice?audio="
            + urllib.parse.quote(base)
            + "&type=2"
        )

        components.html(
            f"""
<audio controls style="width: 230px; margin-top:-0.35rem; margin-bottom:0.75rem;">
  <source src="{audio_url}" type="audio/mpeg">
  æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘æ’­æ”¾ã€‚
</audio>
""",
            height=60,
        )

        # ======== å†™å…¥å†å²è®°å½•ï¼ˆå»é‡ + æ¬¡æ•°ï¼›å†å²é‡Œæš‚æ—¶åªå­˜ IPAï¼Œä¸å­˜é‡Šä¹‰ï¼‰ ========
        history = st.session_state["history"]
        now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        ipa_for_history = ipa_text or ""

        if base in history:
            entry = history[base]
            entry["æ—¶é—´"] = now_str
            entry["æ¬¡æ•°"] += 1
            entry["åŸå§‹è¾“å…¥"] = w
            entry["éŸ³èŠ‚åˆ†éš”"] = pretty
            entry["éŸ³èŠ‚æ•°"] = cnt
            entry["IPA"] = ipa_for_history
        else:
            history[base] = {
                "æ—¶é—´": now_str,
                "æ¬¡æ•°": 1,
                "åŸå§‹è¾“å…¥": w,
                "æ ‡å‡†å•è¯": base,
                "éŸ³èŠ‚åˆ†éš”": pretty,
                "éŸ³èŠ‚æ•°": cnt,
                "IPA": ipa_for_history,
            }

    # å°ç»Ÿè®¡å¡ç‰‡
    st.markdown(
        f"""
        <div style="margin-top:0.8rem; margin-bottom:1.2rem; padding:0.65rem 0.9rem;
                    border-radius:0.75rem; background-color:#020617;
                    border:1px dashed #374151; font-size:0.9rem; color:#E5E7EB;">
          æœ¬æ¬¡è¾“å…¥å…±åŒ…å« <b>{total_words}</b> ä¸ªæœ‰æ•ˆå•è¯ï¼Œåˆè®¡ <b>{total_syllables}</b> ä¸ªéŸ³èŠ‚ã€‚
        </div>
        """,
        unsafe_allow_html=True,
    )

else:
    st.write("ä¾‹å¦‚è¯•è¯•ï¼šcomputer / stereotype / information / pineapple")

# ================== å†å²è®°å½• + å¯¼å‡º ==================

history_dict = st.session_state["history"]

st.markdown("---")
st.markdown("### æŸ¥è¯¢å†å²ï¼ˆæŒ‰å•è¯å»é‡ï¼Œæœ¬æ¬¡è¿è¡Œï¼‰")

if not history_dict:
    st.write("æš‚æ— å†å²è®°å½•ã€‚")
else:
    # æŠŠ dict è½¬æˆåˆ—è¡¨ï¼Œå¹¶æŒ‰â€œæ—¶é—´â€å€’åºï¼ˆæœ€è¿‘çš„åœ¨æœ€ä¸Šï¼‰
    records = list(history_dict.values())
    records_sorted = sorted(records, key=lambda x: x["æ—¶é—´"], reverse=True)

    st.table(records_sorted)

    # ç”Ÿæˆ CSV å†…å®¹
    csv_buffer = io.StringIO()
    writer = csv.writer(csv_buffer)
    headers = ["æ—¶é—´", "æ¬¡æ•°", "åŸå§‹è¾“å…¥", "æ ‡å‡†å•è¯", "éŸ³èŠ‚åˆ†éš”", "éŸ³èŠ‚æ•°", "IPA"]
    writer.writerow(headers)
    # å¯¼å‡ºæ—¶æŒ‰æ—¶é—´æ­£åºå¯¼å‡ºï¼Œæ–¹ä¾¿å¤ä¹ 
    for item in sorted(records, key=lambda x: x["æ—¶é—´"]):
        writer.writerow(
            [
                item["æ—¶é—´"],
                item["æ¬¡æ•°"],
                item["åŸå§‹è¾“å…¥"],
                item["æ ‡å‡†å•è¯"],
                item["éŸ³èŠ‚åˆ†éš”"],
                item["éŸ³èŠ‚æ•°"],
                item["IPA"],
            ]
        )
    csv_bytes = csv_buffer.getvalue().encode("utf-8-sig")

    # ç”Ÿæˆ TXT å†…å®¹ï¼ˆåˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰
    lines = [
        "æ—¶é—´\tæ¬¡æ•°\tåŸå§‹è¾“å…¥\tæ ‡å‡†å•è¯\téŸ³èŠ‚åˆ†éš”\téŸ³èŠ‚æ•°\tIPA",
    ]
    for item in sorted(records, key=lambda x: x["æ—¶é—´"]):
        line = (
            f"{item['æ—¶é—´']}\t{item['æ¬¡æ•°']}\t{item['åŸå§‹è¾“å…¥']}\t{item['æ ‡å‡†å•è¯']}\t"
            f"{item['éŸ³èŠ‚åˆ†éš”']}\t{item['éŸ³èŠ‚æ•°']}\t{item['IPA']}"
        )
        lines.append(line)
    txt_data = "\n".join(lines)

    st.write("")
    st.markdown("**å¯¼å‡ºå†å²è®°å½•ï¼š**")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.download_button(
            "ä¸‹è½½ CSVï¼ˆExcelï¼‰",
            data=csv_bytes,
            file_name="phonics_history.csv",
            mime="text/csv",
        )
    with col2:
        st.download_button(
            "ä¸‹è½½ TXTï¼ˆæ–‡æœ¬ï¼‰",
            data=txt_data,
            file_name="phonics_history.txt",
            mime="text/plain",
        )
    with col3:
        if st.button("æ¸…ç©ºå†å²è®°å½•"):
            st.session_state["history"] = {}
            st.rerun()
